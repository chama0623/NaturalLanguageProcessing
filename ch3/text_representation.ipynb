{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb18282-f058-4af1-ba18-29a2f8928620",
   "metadata": {},
   "source": [
    "# One-hotエンコーディング\n",
    "One-hotエンコーディングを行うことでテキストをベクトル化することができる. One-hotエンコーディングによるテキスト表現は直観的で実装が簡単であるが, ベクトルの大きさが語彙数に比例することによってスパースな表現になる, テキストを固定長で表現できない, 単語間の類似性という概念を持たない, 未知の単語に適応できないという問題点がある."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9c8f48-f0a9-4bf8-82b2-dbb8f1efb3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'bites': 2, 'man': 3, 'eats': 4, 'meat': 5, 'food': 6}\n",
      "man bites dog\n",
      "[[0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "# 小文字化してピリオドを取り除く\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "\n",
    "# vocabの構築\n",
    "vocab={}\n",
    "count = 0\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word not in vocab:\n",
    "            count = count+1\n",
    "            vocab[word] = count\n",
    "print(vocab)\n",
    "\n",
    "def get_onehot_vector(somestring):\n",
    "    onehot_encoded = []\n",
    "    for word in somestring.split():\n",
    "        temp = [0]*len(vocab)\n",
    "        if word in vocab:\n",
    "            temp[vocab[word]-1] = 1\n",
    "        onehot_encoded.append(temp)\n",
    "    return onehot_encoded\n",
    "\n",
    "print(processed_docs[1])\n",
    "print(get_onehot_vector(processed_docs[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27f07c-8e91-4c0c-ace7-4add5e8f9557",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "Bag of Wordsはテキストを単語の集合として表現することでテキスト表現を行う手法である. BoWは同じ単語を含むテキストのベクトル表現が近くなるため文書の類似性を捉えているといえる. また任意の長さの文を固定長の符号で表すことができる. 一方でスパース性の問題や, 同じ意味をもつ異なる単語への類似性がないこと, OOVが処理できない, 語順が失われるという問題がある."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee92744d-9f6c-4160-97ee-2824972572bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n",
      "dog bites man\n",
      "[[1 1 0 0 1 0]]\n",
      "man bites dog\n",
      "[[1 1 0 0 1 0]]\n",
      "dog eats meat\n",
      "[[0 1 1 0 0 1]]\n",
      "man eats food\n",
      "[[0 0 1 1 1 0]]\n",
      "[[0 2 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "# 語彙を表示\n",
    "print(count_vect.vocabulary_)\n",
    "\n",
    "# Bowを表示\n",
    "for i in range(len(processed_docs)):\n",
    "    print(processed_docs[i])\n",
    "    print(bow_rep[i].toarray())\n",
    "    \n",
    "# 新しいテキストに対するBoW\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2d5be-b9e0-424d-b844-951b8b9e04a2",
   "metadata": {},
   "source": [
    "# Bag of N-grams\n",
    "Bag of N-grams(BoN)はテキストを連続するn個の単語に分割することでフレーズや語順を考慮したテキスト表現を作成する方法である. BoNは同じnグラムを含む文書に対する類似性を捉えることができる一方で, nが増加するとスパース性が急速に増加する, OOVが処理できないという問題がある."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0715b362-d691-4afd-9d95-93b283beef06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 3, 'bites': 0, 'man': 12, 'dog bites': 4, 'bites man': 2, 'dog bites man': 5, 'man bites': 13, 'bites dog': 1, 'man bites dog': 14, 'eats': 8, 'meat': 17, 'dog eats': 6, 'eats meat': 10, 'dog eats meat': 7, 'food': 11, 'man eats': 15, 'eats food': 9, 'man eats food': 16}\n"
     ]
    }
   ],
   "source": [
    "# n=1,2,3のときのBoN\n",
    "count_vect = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "# 語彙を表示\n",
    "print(count_vect.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37f1fb69-4c97-4030-942b-c67efda6b06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog bites man\n",
      "[[1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "man bites dog\n",
      "[[1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0]]\n",
      "dog eats meat\n",
      "[[0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1]]\n",
      "man eats food\n",
      "[[0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1 0]]\n",
      "[[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 新しいテキストに対するBoW\n",
    "\n",
    "# BoNを表示\n",
    "for i in range(len(processed_docs)):\n",
    "    print(processed_docs[i])\n",
    "    print(bow_rep[i].toarray())\n",
    "\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae5cca-80e7-42ed-a1d8-cf5879ec8d69",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "TF-IDFはある文書中に登場する単語の頻度TFと, 文書間である単語の頻度を比較するIDFの積で表されるテキスト表現である. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701c22e1-ff46-47ae-9dfb-7f492adc77eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n",
      "dog bites man\n",
      "[[0.65782931 0.53256952 0.         0.         0.53256952 0.        ]]\n",
      "man bites dog\n",
      "[[0.65782931 0.53256952 0.         0.         0.53256952 0.        ]]\n",
      "dog eats meat\n",
      "[[0.         0.44809973 0.55349232 0.         0.         0.70203482]]\n",
      "man eats food\n",
      "[[0.         0.         0.55349232 0.70203482 0.44809973 0.        ]]\n",
      "<bound method CountVectorizer.get_feature_names of TfidfVectorizer()>\n",
      "[1.51082562 1.22314355 1.51082562 1.91629073 1.22314355 1.91629073]\n",
      "[[0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
    "\n",
    "# 語彙を表示\n",
    "print(tfidf.vocabulary_)\n",
    "\n",
    "# TF-IDFを表示\n",
    "for i in range(len(processed_docs)):\n",
    "    print(processed_docs[i])\n",
    "    print(bow_rep_tfidf[i].toarray())\n",
    "\n",
    "print(tfidf.get_feature_names) # 全単語\n",
    "print(tfidf.idf_) # IDF\n",
    "\n",
    "temp = tfidf.transform([\"dog and dog are friends\"])\n",
    "print(temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ff8da-ea99-49c8-8c27-125cedfc7d3b",
   "metadata": {},
   "source": [
    "## 事前学習済み単語埋め込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d82e4e7-4f6a-4e7f-a741-d9e9faaaab01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-04 10:07:26--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.37.86\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.37.86|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1.5G) [application/x-gzip]\n",
      "Saving to: ‘/tmp/input/GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   1.53G  11.0MB/s    in 2m 42s  \n",
      "\n",
      "2022-03-04 10:10:09 (9.71 MB/s) - ‘/tmp/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 事前学習済み単語埋め込みのダウンロード\n",
    "!wget -P /tmp/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf910efa-2776-4716-8072-28e53b51bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "\n",
    "path = \"/tmp/input/GoogleNews-vectors-negative300.bin.gz\"\n",
    "vectors = KeyedVectors.load_word2vec_format(path,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d49377-4b3d-4daa-aa8e-77fa1f375351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gorgeous', 0.8353005051612854), ('lovely', 0.8106936812400818), ('stunningly_beautiful', 0.7329413294792175), ('breathtakingly_beautiful', 0.7231340408325195), ('wonderful', 0.6854086518287659), ('fabulous', 0.6700063943862915), ('loveliest', 0.6612576246261597), ('prettiest', 0.6595001816749573), ('beatiful', 0.6593326330184937), ('magnificent', 0.6591402888298035)]\n"
     ]
    }
   ],
   "source": [
    "# beautifulに類似する単語を取得\n",
    "print(vectors.most_similar(\"beautiful\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27694142-0e23-4b42-8ed4-b38df99642cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01831055,  0.05566406, -0.01153564,  0.07275391,  0.15136719,\n",
       "       -0.06176758,  0.20605469, -0.15332031, -0.05908203,  0.22851562,\n",
       "       -0.06445312, -0.22851562, -0.09472656, -0.03344727,  0.24707031,\n",
       "        0.05541992, -0.00921631,  0.1328125 , -0.15429688,  0.08105469,\n",
       "       -0.07373047,  0.24316406,  0.12353516, -0.09277344,  0.08203125,\n",
       "        0.06494141,  0.15722656,  0.11279297, -0.0612793 , -0.296875  ,\n",
       "       -0.13378906,  0.234375  ,  0.09765625,  0.17773438,  0.06689453,\n",
       "       -0.27539062,  0.06445312, -0.13867188, -0.08886719,  0.171875  ,\n",
       "        0.07861328, -0.10058594,  0.23925781,  0.03808594,  0.18652344,\n",
       "       -0.11279297,  0.22558594,  0.10986328, -0.11865234,  0.02026367,\n",
       "        0.11376953,  0.09570312,  0.29492188,  0.08251953, -0.05444336,\n",
       "       -0.0090332 , -0.0625    , -0.17578125, -0.08154297,  0.01062012,\n",
       "       -0.04736328, -0.08544922, -0.19042969, -0.30273438,  0.07617188,\n",
       "        0.125     , -0.05932617,  0.03833008, -0.03564453,  0.2421875 ,\n",
       "        0.36132812,  0.04760742,  0.00631714, -0.03088379, -0.13964844,\n",
       "        0.22558594, -0.06298828, -0.02636719,  0.1171875 ,  0.33398438,\n",
       "       -0.07666016, -0.06689453,  0.04150391, -0.15136719, -0.22460938,\n",
       "        0.03320312, -0.15332031,  0.07128906,  0.16992188,  0.11572266,\n",
       "       -0.13085938,  0.12451172, -0.20410156,  0.04736328, -0.296875  ,\n",
       "       -0.17480469,  0.00872803, -0.04638672,  0.10791016, -0.203125  ,\n",
       "       -0.27539062,  0.2734375 ,  0.02563477, -0.11035156,  0.0625    ,\n",
       "        0.1953125 ,  0.16015625, -0.13769531, -0.09863281, -0.1953125 ,\n",
       "       -0.22851562,  0.25390625,  0.00915527, -0.03857422,  0.3984375 ,\n",
       "       -0.1796875 ,  0.03833008, -0.24804688,  0.03515625,  0.03881836,\n",
       "        0.03442383, -0.04101562,  0.20214844, -0.03015137, -0.09619141,\n",
       "        0.11669922, -0.06738281,  0.0625    ,  0.10742188,  0.25585938,\n",
       "       -0.21777344,  0.05639648, -0.0065918 ,  0.16113281,  0.11865234,\n",
       "       -0.03088379, -0.11572266,  0.02685547,  0.03100586,  0.09863281,\n",
       "        0.05883789,  0.00634766,  0.11914062,  0.07324219, -0.01586914,\n",
       "        0.18457031,  0.05322266,  0.19824219, -0.22363281, -0.25195312,\n",
       "        0.15039062,  0.22753906,  0.05737305,  0.16992188, -0.22558594,\n",
       "        0.06494141,  0.11914062, -0.06640625, -0.10449219, -0.07226562,\n",
       "       -0.16992188,  0.0625    ,  0.14648438,  0.27148438, -0.02172852,\n",
       "       -0.12695312,  0.18457031, -0.27539062, -0.36523438, -0.03491211,\n",
       "       -0.18554688,  0.23828125, -0.13867188,  0.00296021,  0.04272461,\n",
       "        0.13867188,  0.12207031,  0.05957031, -0.22167969, -0.18945312,\n",
       "       -0.23242188, -0.28710938, -0.00866699, -0.16113281, -0.24316406,\n",
       "        0.05712891, -0.06982422,  0.00053406, -0.10302734, -0.13378906,\n",
       "       -0.16113281,  0.11621094,  0.31640625, -0.02697754, -0.01574707,\n",
       "        0.11425781, -0.04174805,  0.05908203,  0.02661133, -0.08642578,\n",
       "        0.140625  ,  0.09228516, -0.25195312, -0.31445312, -0.05688477,\n",
       "        0.01031494,  0.0234375 , -0.02331543, -0.08056641,  0.01269531,\n",
       "       -0.34179688,  0.17285156, -0.16015625,  0.07763672, -0.03088379,\n",
       "        0.11962891,  0.11767578,  0.20117188, -0.01940918,  0.02172852,\n",
       "        0.23046875,  0.28125   , -0.17675781,  0.02978516,  0.08740234,\n",
       "       -0.06176758,  0.00939941, -0.09277344, -0.203125  ,  0.13085938,\n",
       "       -0.13671875, -0.00500488, -0.04296875,  0.12988281,  0.3515625 ,\n",
       "        0.0402832 , -0.12988281, -0.03173828,  0.28515625,  0.18261719,\n",
       "        0.13867188, -0.16503906, -0.26171875, -0.04345703,  0.0100708 ,\n",
       "        0.08740234,  0.00421143, -0.1328125 , -0.17578125, -0.04321289,\n",
       "       -0.015625  ,  0.16894531,  0.25      ,  0.37109375,  0.19921875,\n",
       "       -0.36132812, -0.10302734, -0.20800781, -0.20117188, -0.01519775,\n",
       "       -0.12207031, -0.12011719, -0.07421875, -0.04345703,  0.14160156,\n",
       "        0.15527344, -0.03027344, -0.09326172, -0.04589844,  0.16796875,\n",
       "       -0.03027344,  0.09179688, -0.10058594,  0.20703125,  0.11376953,\n",
       "       -0.12402344,  0.04003906,  0.06933594, -0.34570312,  0.03881836,\n",
       "        0.16210938,  0.05761719, -0.12792969, -0.05810547,  0.03857422,\n",
       "       -0.11328125, -0.1953125 , -0.28125   , -0.13183594,  0.15722656,\n",
       "       -0.09765625,  0.09619141, -0.09960938, -0.00285339, -0.03637695,\n",
       "        0.15429688,  0.06152344, -0.34570312,  0.11083984,  0.03344727],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ベクトルを表示\n",
    "vectors[\"beautiful\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f000683-1ce0-4b5b-b2bf-9d532a53620f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'practicnlp' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 存在しない単語を検索したとき\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpracticnlp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py:773\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    771\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m key)\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 773\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key):\n\u001b[1;32m    775\u001b[0m         all_keys\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py:438\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py:412\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'practicnlp' not present\""
     ]
    }
   ],
   "source": [
    "# 存在しない単語を検索したとき\n",
    "print(vectors.most_similar(\"practicnlp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d686fc2-d0ca-419d-8c04-5386081ac606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
