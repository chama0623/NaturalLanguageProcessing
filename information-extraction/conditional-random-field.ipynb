{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afcde24b-a160-4364-b267-24ae53552684",
   "metadata": {},
   "source": [
    "# 条件付き確率場(Conditional Random Field;CRF)を用いた固有表現認識器の構築\n",
    "条件付き確率場を用いて固有表現認識器の構築を行う. データは固有表現認識の典型的なデータであるCoNLL-03データセットを用いる. 各データは単語ごとに固有表現か非固有表現かのラベル付けがIOB2表記で行われている. 固有表現の場合の始まりのときB, 固有表現の途中のときI, 非固有表現のときOを表す. このようなラベル付けをされたデータに対してテキスト分類と同様にCRFで学習を行う."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de4cb3-c7fd-415b-8404-33769140086f",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3039062b-c7db-4a8b-8e48-ccb7108b5018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-crfsuite\n",
      "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting eli5\n",
      "  Downloading eli5-0.11.0-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting python-crfsuite>=0.8.3\n",
      "  Downloading python_crfsuite-0.9.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.8/dist-packages (from sklearn-crfsuite) (4.63.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sklearn-crfsuite) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.22.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from eli5) (3.0.3)\n",
      "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.8/dist-packages (from eli5) (21.4.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from eli5) (1.8.0)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from eli5) (0.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->eli5) (2.1.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=a8672598ae56a42521c3d957f1bd3667880b6d17880e3679b11ef06a1157e424\n",
      "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "Successfully built seqeval\n",
      "Installing collected packages: tabulate, python-crfsuite, sklearn-crfsuite, seqeval, eli5\n",
      "Successfully installed eli5-0.11.0 python-crfsuite-0.9.8 seqeval-1.2.2 sklearn-crfsuite-0.3.6 tabulate-0.8.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite seqeval eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355c0057-1757-4732-a777-71e0fae3c01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "import scipy\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695bfef2-428b-4756-9871-9b4d74b3da65",
   "metadata": {},
   "source": [
    "# データセット読み込み\n",
    "データセットは次に示す構造である. まず開始を表す\"-DOCSTART\"から始まる行がある. 次にスペースの行からスペースの行までの間に1文に関するデータが格納されている. データは単語, 品詞, 構文チャンクタグ, IOB2表記 という風になっている. ここでは単語, 品詞を特徴量, IOB2表記をターゲットとして用いる.\n",
    "```\n",
    "-DOCSTART- -X- -X- O\n",
    "\n",
    "EU NNP B-NP B-ORG\n",
    "rejects VBZ B-VP O\n",
    "German JJ B-NP B-MISC\n",
    "call NN I-NP O\n",
    "to TO B-VP O\n",
    "boycott VB I-VP O\n",
    "British JJ B-NP B-MISC\n",
    "lamb NN I-NP O\n",
    ". . O O\n",
    "\n",
    "Peter NNP B-NP B-PER\n",
    "Blackburn NNP I-NP I-PER\n",
    "\n",
    "BRUSSELS NNP B-NP B-LOC\n",
    "1996-08-22 CD I-NP O\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14798da-5c2d-4588-b635-b2736481b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conll(file_path):\n",
    "    sents = []\n",
    "    sent = []\n",
    "    with open(file_path,encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip() # 文字間の空白以外の空白文字を削除\n",
    "            if line.startswith(\"-DOCSTART\"):\n",
    "                continue\n",
    "            if line:\n",
    "                word,pos,_,tag=line.split()\n",
    "                sent.append((word,pos,tag))\n",
    "            else:\n",
    "                if len(sent)==0:\n",
    "                    continue\n",
    "                sents.append(sent)\n",
    "                sent = []\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7189a93-1e15-4989-90fc-9c175ebdffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = load_conll(\"./data/conll2003/en/train.txt\")\n",
    "valid_sents = load_conll(\"./data/conll2003/en/valid.txt\")\n",
    "test_sents = load_conll(\"./data/conll2003/en/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa73b7f4-564c-4336-a615-39bafe6b3a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('EU', 'NNP', 'B-ORG'),\n",
       "  ('rejects', 'VBZ', 'O'),\n",
       "  ('German', 'JJ', 'B-MISC'),\n",
       "  ('call', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('boycott', 'VB', 'O'),\n",
       "  ('British', 'JJ', 'B-MISC'),\n",
       "  ('lamb', 'NN', 'O'),\n",
       "  ('.', '.', 'O')],\n",
       " [('Peter', 'NNP', 'B-PER'), ('Blackburn', 'NNP', 'I-PER')],\n",
       " [('BRUSSELS', 'NNP', 'B-LOC'), ('1996-08-22', 'CD', 'O')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa2e94f1-79ec-46ab-b249-e7ddfd0bd273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041\n",
      "3250\n",
      "3453\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sents))\n",
    "print(len(valid_sents))\n",
    "print(len(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f86c9-b962-436b-a6da-dbe1f360f2af",
   "metadata": {},
   "source": [
    "# 前処理\n",
    "前処理として次の5つを注目単語の前後2単語(ウィンドウサイズ2のコンテキスト)に関して調べる処理を行う.\n",
    "- 小文字化した単語\n",
    "- 大文字だけからなる単語か\n",
    "- 単語の先頭の文字は大文字か\n",
    "- 数字か\n",
    "- 品詞\n",
    "\n",
    "特徴量の生成に用いる関数の凡例\n",
    "```python\n",
    "test_str1 = \"Apple\"\n",
    "test_str2 = \"GREEN\"\n",
    "test_str3 = \"1234\"\n",
    "print(test_str1.lower())\n",
    "print(test_str1.isupper())\n",
    "print(test_str2.isupper())\n",
    "print(test_str1.istitle())\n",
    "print(test_str2.istitle())\n",
    "print(test_str1.isdigit())\n",
    "print(test_str3.isdigit())\n",
    "```\n",
    "\n",
    "実行結果\n",
    "```\n",
    "apple\n",
    "False\n",
    "True\n",
    "True\n",
    "False\n",
    "False\n",
    "True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adc3d9a4-c238-4997-9ea2-7e93062e0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent,i):\n",
    "    word=sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    # 注目単語の特徴量\n",
    "    features = {\n",
    "    \"bias\":1.0,\n",
    "    \"word.lower()\":word.lower(),\n",
    "    \"word.isupper\":word.isupper(),\n",
    "    \"word.istitle\":word.istitle(),\n",
    "    \"word.isdigit\":word.isdigit(),\n",
    "    \"postag\":postag,\n",
    "    }\n",
    "    \n",
    "    # 注目単語の1つ前の単語\n",
    "    if i>0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "        \"-1:word.lower()\":word1.lower(),\n",
    "        \"-1:word.isupper\":word1.isupper(),\n",
    "        \"-1:word.istitle\":word1.istitle(),\n",
    "        \"-1:postag\":postag1,\n",
    "        })\n",
    "    else: # BOSのとき\n",
    "        features[\"BOS\"] = True\n",
    "    \n",
    "    # 注目単語の2つ前の単語\n",
    "    if i>1:\n",
    "        word2 = sent[i-2][0]\n",
    "        postag2 = sent[i-2][1]\n",
    "        features.update({\n",
    "        \"-2:word.lower()\":word2.lower(),\n",
    "        \"-2:word.isupper\":word2.isupper(),\n",
    "        \"-2:word.istitle\":word2.istitle(),\n",
    "        \"-2:postag\":postag2,\n",
    "        })\n",
    "    else: # BOSのとき\n",
    "        features[\"-2:BOS\"] = True\n",
    "        \n",
    "    # 注目単語の1つ後の単語\n",
    "    if i<len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "        \"+1:word.lower()\":word1.lower(),\n",
    "        \"+1:word.isupper\":word1.isupper(),\n",
    "        \"+1:word.istitle\":word1.istitle(),\n",
    "        \"+1:postag\":postag1,\n",
    "        })\n",
    "    else: # EOSのとき\n",
    "        features[\"EOS\"] = True\n",
    "    \n",
    "    # 注目単語の2つ後の単語\n",
    "    if i<len(sent)-2:\n",
    "        word2 = sent[i+2][0]\n",
    "        postag2 = sent[i+2][1]\n",
    "        features.update({\n",
    "        \"+2:word.lower()\":word2.lower(),\n",
    "        \"+2:word.isupper\":word2.isupper(),\n",
    "        \"+2:word.istitle\":word2.istitle(),\n",
    "        \"+2:postag\":postag2,\n",
    "        })\n",
    "    else: # EOSのとき\n",
    "        features[\"+2:EOS\"] = True\n",
    "        \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    \"\"\"引数で与えられたsentのすべてに対して特徴量を計算\"\"\"\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2e58c60-f5f8-4482-8df8-03d20623085d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'eu',\n",
       " 'word.isupper': True,\n",
       " 'word.istitle': False,\n",
       " 'word.isdigit': False,\n",
       " 'postag': 'NNP',\n",
       " 'BOS': True,\n",
       " '-2:BOS': True,\n",
       " '+1:word.lower()': 'rejects',\n",
       " '+1:word.isupper': False,\n",
       " '+1:word.istitle': False,\n",
       " '+1:postag': 'VBZ',\n",
       " '+2:word.lower()': 'german',\n",
       " '+2:word.isupper': False,\n",
       " '+2:word.istitle': True,\n",
       " '+2:postag': 'JJ'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0] # \"EU\"の特徴量を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "357aa83f-2a41-46b0-b351-4a6115ba4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_valid = [sent2features(s) for s in valid_sents]\n",
    "y_valid = [sent2labels(s) for s in valid_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16b728c2-b805-4fd6-b344-7ac6780f2619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bias': 1.0,\n",
       "   'word.lower()': 'eu',\n",
       "   'word.isupper': True,\n",
       "   'word.istitle': False,\n",
       "   'word.isdigit': False,\n",
       "   'postag': 'NNP',\n",
       "   'BOS': True,\n",
       "   '-2:BOS': True,\n",
       "   '+1:word.lower()': 'rejects',\n",
       "   '+1:word.isupper': False,\n",
       "   '+1:word.istitle': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+2:word.lower()': 'german',\n",
       "   '+2:word.isupper': False,\n",
       "   '+2:word.istitle': True,\n",
       "   '+2:postag': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'rejects',\n",
       "   'word.isupper': False,\n",
       "   'word.istitle': False,\n",
       "   'word.isdigit': False,\n",
       "   'postag': 'VBZ',\n",
       "   '-1:word.lower()': 'eu',\n",
       "   '-1:word.isupper': True,\n",
       "   '-1:word.istitle': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-2:BOS': True,\n",
       "   '+1:word.lower()': 'german',\n",
       "   '+1:word.isupper': False,\n",
       "   '+1:word.istitle': True,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+2:word.lower()': 'call',\n",
       "   '+2:word.isupper': False,\n",
       "   '+2:word.istitle': False,\n",
       "   '+2:postag': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'german',\n",
       "   'word.isupper': False,\n",
       "   'word.istitle': True,\n",
       "   'word.isdigit': False,\n",
       "   'postag': 'JJ',\n",
       "   '-1:word.lower()': 'rejects',\n",
       "   '-1:word.isupper': False,\n",
       "   '-1:word.istitle': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-2:word.lower()': 'eu',\n",
       "   '-2:word.isupper': True,\n",
       "   '-2:word.istitle': False,\n",
       "   '-2:postag': 'NNP',\n",
       "   '+1:word.lower()': 'call',\n",
       "   '+1:word.isupper': False,\n",
       "   '+1:word.istitle': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+2:word.lower()': 'to',\n",
       "   '+2:word.isupper': False,\n",
       "   '+2:word.istitle': False,\n",
       "   '+2:postag': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'call',\n",
       "   'word.isupper': False,\n",
       "   'word.istitle': False,\n",
       "   'word.isdigit': False,\n",
       "   'postag': 'NN',\n",
       "   '-1:word.lower()': 'german',\n",
       "   '-1:word.isupper': False,\n",
       "   '-1:word.istitle': True,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-2:word.lower()': 'rejects',\n",
       "   '-2:word.isupper': False,\n",
       "   '-2:word.istitle': False,\n",
       "   '-2:postag': 'VBZ',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.isupper': False,\n",
       "   '+1:word.istitle': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+2:word.lower()': 'boycott',\n",
       "   '+2:word.isupper': False,\n",
       "   '+2:word.istitle': False,\n",
       "   '+2:postag': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word.isupper': False,\n",
       "   'word.istitle': False,\n",
       "   'word.isdigit': False,\n",
       "   'postag': 'TO',\n",
       "   '-1:word.lower()': 'call',\n",
       "   '-1:word.isupper': False,\n",
       "   '-1:word.istitle': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-2:word.lower()': 'german',\n",
       "   '-2:word.isupper': False,\n",
       "   '-2:word.istitle': True,\n",
       "   '-2:postag': 'JJ',\n",
       "   '+1:word.lower()': 'boycott',\n",
       "   '+1:word.isupper': False,\n",
       "   '+1:word.istitle': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+2:word.lower()': 'british',\n",
       "   '+2:word.isupper': False,\n",
       "   '+2:word.istitle': True,\n",
       "   '+2:postag': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'boycott',\n",
       "   'word.isupper': False,\n",
       "   'word.istitle': False,\n",
       "   'word.isdigit': False,\n",
       "   'postag': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.isupper': False,\n",
       "   '-1:word.istitle': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-2:word.lower()': 'call',\n",
       "   '-2:word.isupper': False,\n",
       "   '-2:word.istitle': False,\n",
       "   '-2:postag': 'NN',\n",
       "   '+1:word.lower()': 'british',\n",
       "   '+1:word.isupper': False,\n",
       "   '+1:word.istitle': True,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+2:word.lower()': 'lamb',\n",
       "   '+2:word.isupper': False,\n",
       "   '+2:word.istitle': False,\n",
       "   '+2:postag': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'british',\n",
       "   'word.isupper': False,\n",
       "   'word.istitle': True,\n",
       "   'word.isdigit': False,\n",
       "   'postag': 'JJ',\n",
       "   '-1:word.lower()': 'boycott',\n",
       "   '-1:word.isupper': False,\n",
       "   '-1:word.istitle': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-2:word.lower()': 'to',\n",
       "   '-2:word.isupper': False,\n",
       "   '-2:word.istitle': False,\n",
       "   '-2:postag': 'TO',\n",
       "   '+1:word.lower()': 'lamb',\n",
       "   '+1:word.isupper': False,\n",
       "   '+1:word.istitle': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+2:word.lower()': '.',\n",
       "   '+2:word.isupper': False,\n",
       "   '+2:word.istitle': False,\n",
       "   '+2:postag': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'lamb',\n",
       "   'word.isupper': False,\n",
       "   'word.istitle': False,\n",
       "   'word.isdigit': False,\n",
       "   'postag': 'NN',\n",
       "   '-1:word.lower()': 'british',\n",
       "   '-1:word.isupper': False,\n",
       "   '-1:word.istitle': True,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-2:word.lower()': 'boycott',\n",
       "   '-2:word.isupper': False,\n",
       "   '-2:word.istitle': False,\n",
       "   '-2:postag': 'VB',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.isupper': False,\n",
       "   '+1:word.istitle': False,\n",
       "   '+1:postag': '.',\n",
       "   '+2:EOS': True},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word.isupper': False,\n",
       "   'word.istitle': False,\n",
       "   'word.isdigit': False,\n",
       "   'postag': '.',\n",
       "   '-1:word.lower()': 'lamb',\n",
       "   '-1:word.isupper': False,\n",
       "   '-1:word.istitle': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-2:word.lower()': 'british',\n",
       "   '-2:word.isupper': False,\n",
       "   '-2:word.istitle': True,\n",
       "   '-2:postag': 'JJ',\n",
       "   'EOS': True,\n",
       "   '+2:EOS': True}]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132f8d9-bc42-4a1f-8feb-d83932e6e6fc",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6777d1e0-2aa2-4c20-bea5-decc11057309",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CRF(\n",
    "algorithm=\"lbfgs\",\n",
    "max_iterations=100,\n",
    "all_possible_transitions=False)\n",
    "\n",
    "# validもtrainにして学習\n",
    "try:\n",
    "    model.fit(X_train+X_valid,y_train+y_valid)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1737e94-b8ee-4755-9f95-36178dd33931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.8385    0.7842    0.8104      1668\n",
      "        MISC     0.7602    0.6638    0.7087       702\n",
      "         ORG     0.7256    0.7038    0.7145      1661\n",
      "         PER     0.8041    0.8683    0.8350      1617\n",
      "\n",
      "   micro avg     0.7861    0.7697    0.7778      5648\n",
      "   macro avg     0.7821    0.7550    0.7672      5648\n",
      "weighted avg     0.7857    0.7697    0.7766      5648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b06ec9c2-b65b-4118-af04-376f60c57d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SOCCER', 'NN', 'O') pred : O , ans : O\n",
      "('-', ':', 'O') pred : O , ans : O\n",
      "('JAPAN', 'NNP', 'B-LOC') pred : B-LOC , ans : B-LOC\n",
      "('GET', 'VB', 'O') pred : O , ans : O\n",
      "('LUCKY', 'NNP', 'O') pred : B-ORG , ans : O\n",
      "('WIN', 'NNP', 'O') pred : O , ans : O\n",
      "(',', ',', 'O') pred : O , ans : O\n",
      "('CHINA', 'NNP', 'B-PER') pred : B-LOC , ans : B-PER\n",
      "('IN', 'IN', 'O') pred : O , ans : O\n",
      "('SURPRISE', 'DT', 'O') pred : O , ans : O\n",
      "('DEFEAT', 'NN', 'O') pred : O , ans : O\n",
      "('.', '.', 'O') pred : O , ans : O\n"
     ]
    }
   ],
   "source": [
    "# 予測例を表示\n",
    "text_idx = 0\n",
    "for idx in range(len(test_sents[text_idx])):\n",
    "    print(test_sents[text_idx][idx],\"pred :\",y_pred[text_idx][idx],\", ans :\",y_test[text_idx][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82e712-7e18-4595-86dd-b36f05156654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
