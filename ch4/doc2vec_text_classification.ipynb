{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1daa33a-be0a-4509-9ed2-c5490d653c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc02d1a-1ff8-4df0-895c-48ea90bb30af",
   "metadata": {},
   "source": [
    "# データセットのダウンロード\n",
    "データセットとして40,000件のツイートとその感情13種類のラベル付けされたデータを用いる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8e55c4-b888-4542-9fd9-c677a1ae5af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-10 09:39:36--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/train_data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2479133 (2.4M) [text/plain]\n",
      "Saving to: ‘data/train_data.csv’\n",
      "\n",
      "train_data.csv      100%[===================>]   2.36M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-03-10 09:39:37 (16.3 MB/s) - ‘data/train_data.csv’ saved [2479133/2479133]\n",
      "\n",
      "--2022-03-10 09:39:37--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/test_data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 783640 (765K) [text/plain]\n",
      "Saving to: ‘data/test_data.csv’\n",
      "\n",
      "test_data.csv       100%[===================>] 765.27K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2022-03-10 09:39:38 (9.69 MB/s) - ‘data/test_data.csv’ saved [783640/783640]\n",
      "\n",
      "total 278M\n",
      "drwxr-xr-x 3 root root 4.0K Mar 10 09:39  .\n",
      "drwxr-xr-x 6 root root 4.0K Mar 10 09:36  ..\n",
      "-rw-r--r-- 1 root root  12M Mar  6 14:38  Full-Economic-News-DFE-839861.csv\n",
      "drwxrwxr-x 2 1000 1000 4.0K Mar 30  2015  dbpedia_csv\n",
      "-rw-r--r-- 1 root root  66M Mar  8 15:44  dbpedia_csv.tar.gz\n",
      "-rw-r--r-- 1 root root  22M Mar  8 16:05  dbpedia_test.csv\n",
      "-rw-r--r-- 1 root root 175M Mar  8 16:05  dbpedia_train.csv\n",
      "-rw-r--r-- 1 root root  83K Oct  5  2016 'sentiment labelled sentences.zip'\n",
      "-rw-r--r-- 1 root root  83K Oct  5  2016 'sentiment labelled sentences.zip.1'\n",
      "-rw-r--r-- 1 root root 201K Mar  6 16:50  sentiment_sentences.txt\n",
      "-rw-r--r-- 1 root root 766K Mar 10 09:39  test_data.csv\n",
      "-rw-r--r-- 1 root root 2.4M Mar 10 09:39  train_data.csv\n"
     ]
    }
   ],
   "source": [
    "!wget -P data https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/train_data.csv\n",
    "!wget -P data https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/test_data.csv\n",
    "!ls -lah data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a173e88-47ca-43e9-893c-2a3478cf01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"data/train_data.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f28a4b-0109-4c67-b367-01982c3ac26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worry         7433\n",
       "neutral       6340\n",
       "sadness       4828\n",
       "happiness     2986\n",
       "love          2068\n",
       "surprise      1613\n",
       "hate          1187\n",
       "fun           1088\n",
       "relief        1021\n",
       "empty          659\n",
       "enthusiasm     522\n",
       "boredom        157\n",
       "anger           98\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ターゲットは13種類にラベル付けされている\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1181266f-1295-4175-9771-270201489145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16759, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上位3カテゴリのみに絞る\n",
    "shortlist = [\"neutral\",\"happiness\",\"worry\"]\n",
    "df_subset = df[df[\"sentiment\"].isin(shortlist)]\n",
    "df_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d92d5a-185b-4407-be85-2076828b142a",
   "metadata": {},
   "source": [
    "# 前処理\n",
    "前処理としてmentionの含む個人情報を削除して小文字に変換する処理を行う. そしてストップワードと数字を削除する. 句読点や顔文字は感情を表すから残しておく."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "936dacb7-cf73-41f7-8bb7-4abe92463412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16759 16759\n"
     ]
    }
   ],
   "source": [
    "# strip_handles : Trueのときハンドル名を含む個人情報を削除\n",
    "# preserve_case : 小文字に変換\n",
    "tweeter = TweetTokenizer(strip_handles=True,preserve_case=False)\n",
    "# ストップワード\n",
    "mystopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "# 前処理をまとめた関数\n",
    "def preprocess_corpus(texts):\n",
    "    def remove_stops_digits(tokens):\n",
    "        # 入れ子になった関数。ストップワードと数字をトークンのリストから除去\n",
    "        return [token for token in tokens if token not in mystopwords and not token.isdigit()]\n",
    "    # 上記で定義した関数を使って、Twitterトークナイザーの出力をさらに処理\n",
    "    return [remove_stops_digits(tweeter.tokenize(content)) for content in texts]\n",
    "\n",
    "mydata = preprocess_corpus(df_subset['content'])\n",
    "mycats = df_subset['sentiment']\n",
    "print(len(mydata), len(mycats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3396b6d-d866-444a-8b44-36ffae92e96f",
   "metadata": {},
   "source": [
    "# Doc2Vecの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "360e9612-53e9-4845-ac03-b140dcadcd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data,train_cats,test_cats = train_test_split(\n",
    "mydata,\n",
    "mycats,\n",
    "random_state=1234)\n",
    "\n",
    "# doc2vec形式に変換\n",
    "train_doc2vec = [TaggedDocument((d), tags=[str(i)]) for i, d in enumerate(train_data)]\n",
    "\n",
    "# doc2vecモデルを学習\n",
    "model = Doc2Vec(vector_size=50,alpha=0.025,min_count=5,dm=1,epochs=100)\n",
    "model.build_vocab(train_doc2vec)\n",
    "model.train(train_doc2vec,total_examples=model.corpus_count,epochs=model.epochs)\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eb44aef-4974-4ea4-9406-95d2c1d84d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=[\"caaaaan't\", 'sleep', '...', '3.30', '!', 'wahhhh', '...', 'wanna', 'cry'], tags=['0']),\n",
       " TaggedDocument(words=['based', 'future', 'forgetting', '/', 'ignoring', 'present', ',', 'best', 'keeper', 'according', 'dhoni', 'parthiv'], tags=['1']),\n",
       " TaggedDocument(words=['good', 'morning', '!', 'early', 'bad', 'conscience', ',', 'trying', 'make', 'taking', 'day', 'yesterday', ',', '?', ':p'], tags=['2']),\n",
       " TaggedDocument(words=['hahaha', \"chivalry's\", 'dead', ',', 'rare'], tags=['3']),\n",
       " TaggedDocument(words=['joining', 'twitter'], tags=['4'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_doc2vec[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3769800-b65e-43a0-b555-50c1c3c0188c",
   "metadata": {},
   "source": [
    "# 分類モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46210ce2-6b03-4937-bae5-7d73d3be84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "# 新しい文章に対する表現獲得\n",
    "train_vectors =  [model.infer_vector(list_of_tokens, epochs=50) for list_of_tokens in train_data]\n",
    "test_vectors = [model.infer_vector(list_of_tokens, epochs=50) for list_of_tokens in test_data]\n",
    "\n",
    "logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "logreg.fit(train_vectors,train_cats)\n",
    "preds = logreg.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ccda24b-6c43-4b99-9d01-8c51b8f2d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.35      0.54      0.42       713\n",
      "     neutral       0.47      0.54      0.50      1595\n",
      "       worry       0.61      0.40      0.48      1882\n",
      "\n",
      "    accuracy                           0.48      4190\n",
      "   macro avg       0.47      0.49      0.47      4190\n",
      "weighted avg       0.51      0.48      0.48      4190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_cats, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469c1f1-b0df-4366-9ea2-12df5c352658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
